{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-data-analysis/resources/0dhYG) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Hypothesis Testing\n",
    "This assignment requires more individual learning than previous assignments - you are encouraged to check out the [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/) to find functions or methods you might not have used yet, or ask questions on [Stack Overflow](http://stackoverflow.com/) and tag them as pandas and python related. And of course, the discussion forums are open for interaction with your peers and the course staff.\n",
    "\n",
    "Definitions:\n",
    "* A _quarter_ is a specific three month period, Q1 is January through March, Q2 is April through June, Q3 is July through September, Q4 is October through December.\n",
    "* A _recession_ is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
    "* A _recession bottom_ is the quarter within a recession which had the lowest GDP.\n",
    "* A _university town_ is a city which has a high percentage of university students compared to the total population of the city.\n",
    "\n",
    "**Hypothesis**: University towns have their mean housing prices less effected by recessions. Run a t-test to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom. (`price_ratio=quarter_before_recession/recession_bottom`)\n",
    "\n",
    "The following data files are available for this assignment:\n",
    "* From the [Zillow research data site](http://www.zillow.com/research/data/) there is housing data for the United States. In particular the datafile for [all homes at a city level](http://files.zillowstatic.com/research/public/City/City_Zhvi_AllHomes.csv), ```City_Zhvi_AllHomes.csv```, has median home sale prices at a fine grained level.\n",
    "* From the Wikipedia page on college towns is a list of [university towns in the United States](https://en.wikipedia.org/wiki/List_of_college_towns#College_towns_in_the_United_States) which has been copy and pasted into the file ```university_towns.txt```.\n",
    "* From Bureau of Economic Analysis, US Department of Commerce, the [GDP over time](http://www.bea.gov/national/index.htm#gdp) of the United States in current dollars (use the chained value in 2009 dollars), in quarterly intervals, in the file ```gdplev.xls```. For this assignment, only look at GDP data from the first quarter of 2000 onward.\n",
    "\n",
    "Each function in this assignment below is worth 10%, with the exception of ```run_ttest()```, which is worth 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use this dictionary to map state names to two letter acronyms\n",
    "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         State           RegionName Acronyms\n0      Alabama               Auburn       AL\n1      Alabama             Florence       AL\n2      Alabama         Jacksonville       AL\n3      Alabama           Livingston       AL\n4      Alabama           Montevallo       AL\n5      Alabama                 Troy       AL\n6      Alabama           Tuscaloosa       AL\n7      Alabama             Tuskegee       AL\n8       Alaska            Fairbanks       AK\n9      Arizona            Flagstaff       AZ\n10     Arizona                Tempe       AZ\n11     Arizona               Tucson       AZ\n12    Arkansas          Arkadelphia       AR\n13    Arkansas               Conway       AR\n14    Arkansas         Fayetteville       AR\n15    Arkansas            Jonesboro       AR\n16    Arkansas             Magnolia       AR\n17    Arkansas           Monticello       AR\n18    Arkansas         Russellville       AR\n19    Arkansas               Searcy       AR\n20  California               Angwin       CA\n21  California               Arcata       CA\n22  California             Berkeley       CA\n23  California                Chico       CA\n24  California            Claremont       CA\n25  California               Cotati       CA\n26  California                Davis       CA\n27  California               Irvine       CA\n28  California           Isla Vista       CA\n29  California      University Park       CA\n30  California               Merced       CA\n31  California               Orange       CA\n32  California            Palo Alto       CA\n33  California               Pomona       CA\n34  California             Redlands       CA\n35  California            Riverside       CA\n36  California           Sacramento       CA\n37  California  University District       CA\n38  California            San Diego       CA\n39  California      San Luis Obispo       CA\n40  California        Santa Barbara       CA\n41  California           Santa Cruz       CA\n42  California              Turlock       CA\n43  California             Westwood       CA\n44  California             Whittier       CA\n45    Colorado              Alamosa       CO\n46    Colorado              Boulder       CO\n47    Colorado              Durango       CO\n48    Colorado         Fort Collins       CO\n49    Colorado               Golden       CO",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>RegionName</th>\n      <th>Acronyms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>Auburn</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>Florence</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alabama</td>\n      <td>Jacksonville</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alabama</td>\n      <td>Livingston</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alabama</td>\n      <td>Montevallo</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Alabama</td>\n      <td>Troy</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Alabama</td>\n      <td>Tuscaloosa</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Alabama</td>\n      <td>Tuskegee</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Alaska</td>\n      <td>Fairbanks</td>\n      <td>AK</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Arizona</td>\n      <td>Flagstaff</td>\n      <td>AZ</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Arizona</td>\n      <td>Tempe</td>\n      <td>AZ</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Arizona</td>\n      <td>Tucson</td>\n      <td>AZ</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Arkansas</td>\n      <td>Arkadelphia</td>\n      <td>AR</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Arkansas</td>\n      <td>Conway</td>\n      <td>AR</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Arkansas</td>\n      <td>Fayetteville</td>\n      <td>AR</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Arkansas</td>\n      <td>Jonesboro</td>\n      <td>AR</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Arkansas</td>\n      <td>Magnolia</td>\n      <td>AR</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Arkansas</td>\n      <td>Monticello</td>\n      <td>AR</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Arkansas</td>\n      <td>Russellville</td>\n      <td>AR</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Arkansas</td>\n      <td>Searcy</td>\n      <td>AR</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>California</td>\n      <td>Angwin</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>California</td>\n      <td>Arcata</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>California</td>\n      <td>Berkeley</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>California</td>\n      <td>Chico</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>California</td>\n      <td>Claremont</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>California</td>\n      <td>Cotati</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>California</td>\n      <td>Davis</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>California</td>\n      <td>Irvine</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>California</td>\n      <td>Isla Vista</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>California</td>\n      <td>University Park</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>California</td>\n      <td>Merced</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>California</td>\n      <td>Orange</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>California</td>\n      <td>Palo Alto</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>California</td>\n      <td>Pomona</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>California</td>\n      <td>Redlands</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>California</td>\n      <td>Riverside</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>California</td>\n      <td>Sacramento</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>California</td>\n      <td>University District</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>California</td>\n      <td>San Diego</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>California</td>\n      <td>San Luis Obispo</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>California</td>\n      <td>Santa Barbara</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>California</td>\n      <td>Santa Cruz</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>California</td>\n      <td>Turlock</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>California</td>\n      <td>Westwood</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>California</td>\n      <td>Whittier</td>\n      <td>CA</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Colorado</td>\n      <td>Alamosa</td>\n      <td>CO</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Colorado</td>\n      <td>Boulder</td>\n      <td>CO</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>Colorado</td>\n      <td>Durango</td>\n      <td>CO</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Colorado</td>\n      <td>Fort Collins</td>\n      <td>CO</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>Colorado</td>\n      <td>Golden</td>\n      <td>CO</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "def get_list_of_university_towns():\n",
    "    '''Returns a DataFrame of towns and the states they are in from the \n",
    "    university_towns.txt list. The format of the DataFrame should be:\n",
    "    DataFrame( [ [\"Michigan\", \"Ann Arbor\"], [\"Michigan\", \"Yipsilanti\"] ], \n",
    "    columns=[\"State\", \"RegionName\"]  )\n",
    "    \n",
    "    The following cleaning needs to be done:\n",
    "\n",
    "    1. For \"State\", removing characters from \"[\" to the end.\n",
    "    2. For \"RegionName\", when applicable, removing every character from \" (\" to the end.\n",
    "    3. Depending on how you read the data, you may need to remove newline character '\\n'. '''\n",
    "\n",
    "    univ_towns = pd.read_csv('university_towns.txt',header=None,names=['Data'])\n",
    "    univ_towns['Match'] = univ_towns['Data'].str.contains('edit')    \n",
    "    univ_towns['State'] = univ_towns['Data'].where(univ_towns['Match'] == True)\n",
    "    univ_towns['State']=univ_towns['State'].str.replace('\\[edit]', '')\n",
    "    states_iter = univ_towns['State'].dropna().values    \n",
    "    rangeInSt = univ_towns['Match'].values\n",
    "    i = 0\n",
    "    final_states = [states_iter[i]]\n",
    "    for j in range(1,len(rangeInSt)):\n",
    "        if rangeInSt[j] == True:\n",
    "            i+=1\n",
    "            final_states.append(states_iter[i])\n",
    "        else:\n",
    "            i+=0\n",
    "            final_states.append(states_iter[i])\n",
    "    univ_towns['State'] = final_states\n",
    "    univ_towns['RegionName'] = univ_towns['Data'].where(univ_towns['Match'] == False)\n",
    "    univ_towns= univ_towns.dropna()\n",
    "    univ_towns['RegionName'] = univ_towns['RegionName'].str.replace(pat=r'\\s\\(.*', repl='')\n",
    "    univ_towns = univ_towns.drop(['Data','Match'],1)\n",
    "    df_states = pd.DataFrame({\n",
    "      \"State\": list(states.values()),\n",
    "      \"Acronyms\": list(states.keys())\n",
    "    })\n",
    "    answer = pd.merge(univ_towns,df_states,how='left')\n",
    "    return answer.head(50)\n",
    "\n",
    "get_list_of_university_towns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2008q3'"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "def get_recession_start():\n",
    "  \n",
    "    '''Returns the year and quarter of the recession start time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    data = pd.read_excel('gdplev.xls',skiprows=219,usecols=('e:g'))\n",
    "    data.columns = ['Quarter','b','GDP']\n",
    "    data = data.drop(['b'],1)\n",
    "    gdp_iter = data['GDP'].values\n",
    "    init = 0\n",
    "    for i in range (0,len(gdp_iter)):\n",
    "        if gdp_iter[i] - gdp_iter[i-1]<0:\n",
    "            init = gdp_iter[i-1] - gdp_iter[i-2]\n",
    "            if init < 0:\n",
    "                #print(i)\n",
    "                start = i-1\n",
    "                break               \n",
    "    start_res = data['Quarter'].loc[start]\n",
    "    return start_res\n",
    "get_recession_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2009q4'"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "def get_recession_end():   \n",
    "    '''Returns the year and quarter of the recession end time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    data = pd.read_excel('gdplev.xls',skiprows=219,usecols=('e:g'))\n",
    "    data.columns = ['Year/Quarter','b','GDP']\n",
    "    data = data.drop(['b'],1)\n",
    "    gdp_iter = data['GDP'].values\n",
    "    init = 0\n",
    "    for i in range (33,len(gdp_iter)):\n",
    "        if gdp_iter[i] - gdp_iter[i-1]>0:\n",
    "            init = gdp_iter[i-1] - gdp_iter[i-2]\n",
    "            if init > 0:\n",
    "                #print(i)\n",
    "                end = i\n",
    "                break\n",
    "    end_res = data['Year/Quarter'].loc[end]\n",
    "    return end_res\n",
    "get_recession_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2009q2'"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "def get_recession_bottom():\n",
    "    '''Returns the year and quarter of the recession bottom time as a \n",
    "    string value in a format such as 2005q3'''\n",
    "    data = pd.read_excel('gdplev.xls',skiprows=219,usecols ='e:g')\n",
    "    data.columns = ['Year/Quarter','b','GDP']\n",
    "    data = data.drop(['b'],1)\n",
    "    data = data[33:40]\n",
    "    bottom = data.loc[data['GDP'] == data['GDP'].min(),'Year/Quarter'].iloc[0]\n",
    "    return  bottom\n",
    "get_recession_bottom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                              2000q1         2000q2         2000q3  \\\nState    RegionName                                                  \nOhio     Columbus       94366.666667   95833.333333   97133.333333   \n         Cleveland      67466.666667   67933.333333   68300.000000   \n         Toledo         65100.000000   67000.000000   68533.333333   \n         Akron          70100.000000   71666.666667   71866.666667   \n         Dayton                  NaN            NaN            NaN   \n...                              ...            ...            ...   \nVirginia Linden        121700.000000  125200.000000  125800.000000   \n         Bumpass       127300.000000  127966.666667  128866.666667   \n         Greenville    114833.333333  116966.666667  115200.000000   \n         Mount Sidney  137766.666667  136866.666667  134500.000000   \n         Henrico       128566.666667  130766.666667  132266.666667   \n\n                              2000q4         2001q1         2001q2  \\\nState    RegionName                                                  \nOhio     Columbus       98266.666667   99400.000000  100266.666667   \n         Cleveland      68700.000000   68933.333333   69233.333333   \n         Toledo         70100.000000   70800.000000   71800.000000   \n         Akron          72300.000000   72833.333333   73533.333333   \n         Dayton                  NaN            NaN            NaN   \n...                              ...            ...            ...   \nVirginia Linden        122366.666667  122700.000000  123633.333333   \n         Bumpass       130833.333333  132866.666667  136333.333333   \n         Greenville    114033.333333  119733.333333  120266.666667   \n         Mount Sidney  133633.333333  136100.000000  139800.000000   \n         Henrico       133266.666667  135233.333333  136733.333333   \n\n                              2001q3         2001q4         2002q1  \\\nState    RegionName                                                  \nOhio     Columbus      101066.666667  102200.000000  103400.000000   \n         Cleveland      69566.666667   69966.666667   70566.666667   \n         Toledo         73300.000000   73833.333333   74600.000000   \n         Akron          73933.333333   74066.666667   74500.000000   \n         Dayton                  NaN            NaN            NaN   \n...                              ...            ...            ...   \nVirginia Linden        126400.000000  130033.333333  134600.000000   \n         Bumpass       137933.333333  140566.666667  143600.000000   \n         Greenville    123000.000000  124166.666667  122566.666667   \n         Mount Sidney  143200.000000  145066.666667  142000.000000   \n         Henrico       138600.000000  141333.333333  143533.333333   \n\n                              2002q2  ...         2014q2         2014q3  \\\nState    RegionName                   ...                                 \nOhio     Columbus      104800.000000  ...  103133.333333  104500.000000   \n         Cleveland      71233.333333  ...   52166.666667   52033.333333   \n         Toledo         75200.000000  ...   55066.666667   55700.000000   \n         Akron          75133.333333  ...   62800.000000   62766.666667   \n         Dayton                  NaN  ...   51133.333333   50333.333333   \n...                              ...  ...            ...            ...   \nVirginia Linden        137700.000000  ...  177500.000000  176866.666667   \n         Bumpass       146100.000000  ...  214533.333333  218900.000000   \n         Greenville    122833.333333  ...  161700.000000  160233.333333   \n         Mount Sidney  143700.000000  ...  217966.666667  212333.333333   \n         Henrico       146133.333333  ...  201633.333333  204000.000000   \n\n                              2014q4         2015q1         2015q2  \\\nState    RegionName                                                  \nOhio     Columbus      106433.333333  107866.666667  109433.333333   \n         Cleveland      52500.000000   52333.333333   52333.333333   \n         Toledo         56000.000000   55833.333333   55933.333333   \n         Akron          62800.000000   61933.333333   61833.333333   \n         Dayton         49900.000000   49866.666667   50000.000000   \n...                              ...            ...            ...   \nVirginia Linden        179033.333333  178866.666667  177233.333333   \n         Bumpass       221366.666667  221366.666667  222233.333333   \n         Greenville    158666.666667  158433.333333  162266.666667   \n         Mount Sidney  211433.333333  212233.333333  220866.666667   \n         Henrico       205900.000000  206566.666667  210433.333333   \n\n                              2015q3         2015q4         2016q1  \\\nState    RegionName                                                  \nOhio     Columbus      111566.666667  115000.000000  116700.000000   \n         Cleveland      51933.333333   51566.666667   50833.333333   \n         Toledo         56133.333333   56933.333333   56833.333333   \n         Akron          61600.000000   62200.000000   62133.333333   \n         Dayton         50000.000000   50700.000000   50633.333333   \n...                              ...            ...            ...   \nVirginia Linden        179633.333333  185466.666667  191633.333333   \n         Bumpass       225066.666667  226600.000000  224633.333333   \n         Greenville    164500.000000  165733.333333  169200.000000   \n         Mount Sidney  224133.333333  223600.000000  220633.333333   \n         Henrico       212100.000000  213966.666667  216033.333333   \n\n                              2016q2    2016q3  \nState    RegionName                             \nOhio     Columbus      118200.000000  120100.0  \n         Cleveland      51400.000000   52650.0  \n         Toledo         56800.000000   58200.0  \n         Akron          62400.000000   62750.0  \n         Dayton         50833.333333   51800.0  \n...                              ...       ...  \nVirginia Linden        197300.000000  197700.0  \n         Bumpass       225433.333333  226850.0  \n         Greenville    172033.333333  172650.0  \n         Mount Sidney  221733.333333  222700.0  \n         Henrico       216200.000000  220150.0  \n\n[10730 rows x 67 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>2000q1</th>\n      <th>2000q2</th>\n      <th>2000q3</th>\n      <th>2000q4</th>\n      <th>2001q1</th>\n      <th>2001q2</th>\n      <th>2001q3</th>\n      <th>2001q4</th>\n      <th>2002q1</th>\n      <th>2002q2</th>\n      <th>...</th>\n      <th>2014q2</th>\n      <th>2014q3</th>\n      <th>2014q4</th>\n      <th>2015q1</th>\n      <th>2015q2</th>\n      <th>2015q3</th>\n      <th>2015q4</th>\n      <th>2016q1</th>\n      <th>2016q2</th>\n      <th>2016q3</th>\n    </tr>\n    <tr>\n      <th>State</th>\n      <th>RegionName</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Ohio</th>\n      <th>Columbus</th>\n      <td>94366.666667</td>\n      <td>95833.333333</td>\n      <td>97133.333333</td>\n      <td>98266.666667</td>\n      <td>99400.000000</td>\n      <td>100266.666667</td>\n      <td>101066.666667</td>\n      <td>102200.000000</td>\n      <td>103400.000000</td>\n      <td>104800.000000</td>\n      <td>...</td>\n      <td>103133.333333</td>\n      <td>104500.000000</td>\n      <td>106433.333333</td>\n      <td>107866.666667</td>\n      <td>109433.333333</td>\n      <td>111566.666667</td>\n      <td>115000.000000</td>\n      <td>116700.000000</td>\n      <td>118200.000000</td>\n      <td>120100.0</td>\n    </tr>\n    <tr>\n      <th>Cleveland</th>\n      <td>67466.666667</td>\n      <td>67933.333333</td>\n      <td>68300.000000</td>\n      <td>68700.000000</td>\n      <td>68933.333333</td>\n      <td>69233.333333</td>\n      <td>69566.666667</td>\n      <td>69966.666667</td>\n      <td>70566.666667</td>\n      <td>71233.333333</td>\n      <td>...</td>\n      <td>52166.666667</td>\n      <td>52033.333333</td>\n      <td>52500.000000</td>\n      <td>52333.333333</td>\n      <td>52333.333333</td>\n      <td>51933.333333</td>\n      <td>51566.666667</td>\n      <td>50833.333333</td>\n      <td>51400.000000</td>\n      <td>52650.0</td>\n    </tr>\n    <tr>\n      <th>Toledo</th>\n      <td>65100.000000</td>\n      <td>67000.000000</td>\n      <td>68533.333333</td>\n      <td>70100.000000</td>\n      <td>70800.000000</td>\n      <td>71800.000000</td>\n      <td>73300.000000</td>\n      <td>73833.333333</td>\n      <td>74600.000000</td>\n      <td>75200.000000</td>\n      <td>...</td>\n      <td>55066.666667</td>\n      <td>55700.000000</td>\n      <td>56000.000000</td>\n      <td>55833.333333</td>\n      <td>55933.333333</td>\n      <td>56133.333333</td>\n      <td>56933.333333</td>\n      <td>56833.333333</td>\n      <td>56800.000000</td>\n      <td>58200.0</td>\n    </tr>\n    <tr>\n      <th>Akron</th>\n      <td>70100.000000</td>\n      <td>71666.666667</td>\n      <td>71866.666667</td>\n      <td>72300.000000</td>\n      <td>72833.333333</td>\n      <td>73533.333333</td>\n      <td>73933.333333</td>\n      <td>74066.666667</td>\n      <td>74500.000000</td>\n      <td>75133.333333</td>\n      <td>...</td>\n      <td>62800.000000</td>\n      <td>62766.666667</td>\n      <td>62800.000000</td>\n      <td>61933.333333</td>\n      <td>61833.333333</td>\n      <td>61600.000000</td>\n      <td>62200.000000</td>\n      <td>62133.333333</td>\n      <td>62400.000000</td>\n      <td>62750.0</td>\n    </tr>\n    <tr>\n      <th>Dayton</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>51133.333333</td>\n      <td>50333.333333</td>\n      <td>49900.000000</td>\n      <td>49866.666667</td>\n      <td>50000.000000</td>\n      <td>50000.000000</td>\n      <td>50700.000000</td>\n      <td>50633.333333</td>\n      <td>50833.333333</td>\n      <td>51800.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Virginia</th>\n      <th>Linden</th>\n      <td>121700.000000</td>\n      <td>125200.000000</td>\n      <td>125800.000000</td>\n      <td>122366.666667</td>\n      <td>122700.000000</td>\n      <td>123633.333333</td>\n      <td>126400.000000</td>\n      <td>130033.333333</td>\n      <td>134600.000000</td>\n      <td>137700.000000</td>\n      <td>...</td>\n      <td>177500.000000</td>\n      <td>176866.666667</td>\n      <td>179033.333333</td>\n      <td>178866.666667</td>\n      <td>177233.333333</td>\n      <td>179633.333333</td>\n      <td>185466.666667</td>\n      <td>191633.333333</td>\n      <td>197300.000000</td>\n      <td>197700.0</td>\n    </tr>\n    <tr>\n      <th>Bumpass</th>\n      <td>127300.000000</td>\n      <td>127966.666667</td>\n      <td>128866.666667</td>\n      <td>130833.333333</td>\n      <td>132866.666667</td>\n      <td>136333.333333</td>\n      <td>137933.333333</td>\n      <td>140566.666667</td>\n      <td>143600.000000</td>\n      <td>146100.000000</td>\n      <td>...</td>\n      <td>214533.333333</td>\n      <td>218900.000000</td>\n      <td>221366.666667</td>\n      <td>221366.666667</td>\n      <td>222233.333333</td>\n      <td>225066.666667</td>\n      <td>226600.000000</td>\n      <td>224633.333333</td>\n      <td>225433.333333</td>\n      <td>226850.0</td>\n    </tr>\n    <tr>\n      <th>Greenville</th>\n      <td>114833.333333</td>\n      <td>116966.666667</td>\n      <td>115200.000000</td>\n      <td>114033.333333</td>\n      <td>119733.333333</td>\n      <td>120266.666667</td>\n      <td>123000.000000</td>\n      <td>124166.666667</td>\n      <td>122566.666667</td>\n      <td>122833.333333</td>\n      <td>...</td>\n      <td>161700.000000</td>\n      <td>160233.333333</td>\n      <td>158666.666667</td>\n      <td>158433.333333</td>\n      <td>162266.666667</td>\n      <td>164500.000000</td>\n      <td>165733.333333</td>\n      <td>169200.000000</td>\n      <td>172033.333333</td>\n      <td>172650.0</td>\n    </tr>\n    <tr>\n      <th>Mount Sidney</th>\n      <td>137766.666667</td>\n      <td>136866.666667</td>\n      <td>134500.000000</td>\n      <td>133633.333333</td>\n      <td>136100.000000</td>\n      <td>139800.000000</td>\n      <td>143200.000000</td>\n      <td>145066.666667</td>\n      <td>142000.000000</td>\n      <td>143700.000000</td>\n      <td>...</td>\n      <td>217966.666667</td>\n      <td>212333.333333</td>\n      <td>211433.333333</td>\n      <td>212233.333333</td>\n      <td>220866.666667</td>\n      <td>224133.333333</td>\n      <td>223600.000000</td>\n      <td>220633.333333</td>\n      <td>221733.333333</td>\n      <td>222700.0</td>\n    </tr>\n    <tr>\n      <th>Henrico</th>\n      <td>128566.666667</td>\n      <td>130766.666667</td>\n      <td>132266.666667</td>\n      <td>133266.666667</td>\n      <td>135233.333333</td>\n      <td>136733.333333</td>\n      <td>138600.000000</td>\n      <td>141333.333333</td>\n      <td>143533.333333</td>\n      <td>146133.333333</td>\n      <td>...</td>\n      <td>201633.333333</td>\n      <td>204000.000000</td>\n      <td>205900.000000</td>\n      <td>206566.666667</td>\n      <td>210433.333333</td>\n      <td>212100.000000</td>\n      <td>213966.666667</td>\n      <td>216033.333333</td>\n      <td>216200.000000</td>\n      <td>220150.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10730 rows × 67 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "def convert_housing_data_to_quarters():\n",
    "    '''Converts the housing data to quarters and returns it as mean \n",
    "    values in a dataframe. This dataframe should be a dataframe with\n",
    "    columns for 2000q1 through 2016q3, and should have a multi-index\n",
    "    in the shape of [\"State\",\"RegionName\"].    \n",
    "    Note: Quarters are defined in the assignment description, they are\n",
    "    not arbitrary three month periods.    \n",
    "    The resulting dataframe should have 67 columns, and 10,730 rows.\n",
    "    '''\n",
    "    \n",
    "    data = pd.read_csv('City_Zhvi_AllHomes.csv')\n",
    "    data = data.drop(['RegionID','Metro','CountyName','SizeRank'],1)\n",
    "    data = data.set_index(['State','RegionName'])\n",
    "    data = data.loc[:,'2000-01':'2016-09']\n",
    "    housing = (data.groupby(pd.PeriodIndex(data.columns, freq='Q'), axis=1)\n",
    "                                                                           .mean()\n",
    "                                                                           .rename(columns=lambda x: str(x).lower()))\n",
    "\n",
    "    housing = housing.reset_index()\n",
    "    df_states = pd.DataFrame({\n",
    "      \"State\": list(states.values()),\n",
    "      \"Acronyms\": list(states.keys())\n",
    "    })\n",
    "    #df_states = df_states.set_index('State')\n",
    "\n",
    "    answer = pd.merge(df_states,housing, how = 'inner',left_on=['Acronyms'] ,right_on = ['State'])\n",
    "    answer = answer.drop(['State_y','Acronyms'], 1)\n",
    "    answer = answer.rename(columns = {'State_x':'State'}).set_index(['State','RegionName'])\n",
    "    return answer\n",
    "convert_housing_data_to_quarters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Ttest_indResult(statistic=-2.7582703861390776, pvalue=0.005821494237532901)"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "def run_ttest():\n",
    "    '''First creates new data showing the decline or growth of housing prices\n",
    "    between the recession start and the recession bottom. Then runs a ttest\n",
    "    comparing the university town values to the non-university towns values, \n",
    "    return whether the alternative hypothesis (that the two groups are the same)\n",
    "    is true or not as well as the p-value of the confidence. \n",
    "    \n",
    "    Return the tuple (different, p, better) where different=True if the t-test is\n",
    "    True at a p<0.01 (we reject the null hypothesis), or different=False if \n",
    "    otherwise (we cannot reject the null hypothesis). The variable p should\n",
    "    be equal to the exact p value returned from scipy.stats.ttest_ind(). The\n",
    "    value for better should be either \"university town\" or \"non-university town\"\n",
    "    depending on which has a lower mean price ratio (which is equivilent to a\n",
    "    reduced market loss).'''\n",
    "    \n",
    "    housing = convert_housing_data_to_quarters()\n",
    "    univ_towns = get_list_of_university_towns()\n",
    "    df_states = pd.DataFrame({\n",
    "        \"State\": list(states.values()),\n",
    "        \"Acronym\": list(states.keys())\n",
    "    })\n",
    "    univ_towns = pd.merge(univ_towns,df_states,how='left')#.drop('State',1).rename(columns = {'Acronym':'State'})\n",
    "    start_res = get_recession_start()\n",
    "    end_res = get_recession_end()\n",
    "    res_bottom = get_recession_bottom()    \n",
    "    housing = housing.loc[:,'2008q3':res_bottom].drop('2009q1',axis = 1)\n",
    "    housing = housing.reset_index()\n",
    "    housing['Price Ratio'] = housing['2008q3'] / housing[res_bottom]  \n",
    "    univ_housing = pd.merge(univ_towns,housing,how = 'outer',left_on = ['State','RegionName'],right_on = ['State','RegionName'],indicator = True)\n",
    "    university_towns_values = univ_housing[(univ_housing['_merge'] == 'both')]\n",
    "    non_university_towns_values = univ_housing[(univ_housing['_merge'] == 'right_only')]\n",
    "    university_town = university_towns_values['Price Ratio']\n",
    "    non_university_town = non_university_towns_values['Price Ratio']\n",
    "    test = ttest_ind(university_town,non_university_town,nan_policy='omit')\n",
    "\n",
    "    differet = None\n",
    "    p = test[1]\n",
    "    better = None\n",
    "    if test[1] < 0.01:\n",
    "        differet = True\n",
    "    else:\n",
    "        differet = False\n",
    "    if test[0] < 0:\n",
    "        better = 'university town'\n",
    "    else:\n",
    "        better = 'non-university town'\n",
    "    answer = (differet,p,better)\n",
    "    \n",
    "    return test\n",
    "run_ttest() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         State     RegionName StateAcronyms\n0      Alabama         Auburn            AL\n1      Alabama       Florence            AL\n2      Alabama   Jacksonville            AL\n3      Alabama     Livingston            AL\n4      Alabama     Montevallo            AL\n..         ...            ...           ...\n512  Wisconsin    River Falls            WI\n513  Wisconsin  Stevens Point            WI\n514  Wisconsin       Waukesha            WI\n515  Wisconsin     Whitewater            WI\n516    Wyoming        Laramie            WY\n\n[517 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>RegionName</th>\n      <th>StateAcronyms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>Auburn</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>Florence</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alabama</td>\n      <td>Jacksonville</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alabama</td>\n      <td>Livingston</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alabama</td>\n      <td>Montevallo</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>512</th>\n      <td>Wisconsin</td>\n      <td>River Falls</td>\n      <td>WI</td>\n    </tr>\n    <tr>\n      <th>513</th>\n      <td>Wisconsin</td>\n      <td>Stevens Point</td>\n      <td>WI</td>\n    </tr>\n    <tr>\n      <th>514</th>\n      <td>Wisconsin</td>\n      <td>Waukesha</td>\n      <td>WI</td>\n    </tr>\n    <tr>\n      <th>515</th>\n      <td>Wisconsin</td>\n      <td>Whitewater</td>\n      <td>WI</td>\n    </tr>\n    <tr>\n      <th>516</th>\n      <td>Wyoming</td>\n      <td>Laramie</td>\n      <td>WY</td>\n    </tr>\n  </tbody>\n</table>\n<p>517 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}\n",
    "\n",
    "def get_list_of_university_towns():\n",
    "  \"\"\"\n",
    "  Returns a DataFrame of towns and the states they are in from the \n",
    "  university_towns.txt list. The format of the DataFrame should be:\n",
    "  DataFrame( [ [\"Michigan\", \"Ann Arbor\"], [\"Michigan\", \"Yipsilanti\"] ], \n",
    "  columns=[\"State\", \"RegionName\"]  )\n",
    "    \n",
    "  The following cleaning needs to be done:\n",
    "  1. For \"State\", removing characters from \"[\" to the end.\n",
    "  2. For \"RegionName\", when applicable, removing every character from \" (\" to the end.\n",
    "  3. Depending on how you read the data, you may need to remove newline character '\\n'. \n",
    "  \"\"\"\n",
    "  df = pd.read_table('https://storage.googleapis.com/um_ds_intro/university_towns.txt', header=None)\n",
    "  df.columns = ['StateRegion']\n",
    "  df['StateFlag'] = df['StateRegion'].str.contains(pat=r'\\[edit\\]')\n",
    "  df_states = df[df['StateFlag'] == True]\n",
    "  # 找出不重複州名 -------------\n",
    "  States = df_states['StateRegion'].str.replace(pat=r'\\[edit\\]', repl='').unique()\n",
    "  StateFlags = df['StateFlag'].values\n",
    "  j = 0\n",
    "  StateMatchRegion = [States[j]]\n",
    "  # 分隔州名與區域名的邏輯 -------------\n",
    "  for i in range(1, len(StateFlags)):\n",
    "    if StateFlags[i] == True:\n",
    "      j += 1\n",
    "      StateMatchRegion.append(States[j])\n",
    "    else:\n",
    "      j += 0\n",
    "      StateMatchRegion.append(States[j])\n",
    "  # 清理資料 -------------\n",
    "  df['StateMatchRegion'] = StateMatchRegion\n",
    "  df['RegionName'] = df['StateRegion'].str.replace(pat=r'\\s\\(.*', repl='')\n",
    "  ans = df[df['StateFlag'] == False]\n",
    "  ans = ans.drop(['StateRegion', 'StateFlag'], axis=1)\n",
    "  ans.columns = ['State', 'RegionName']\n",
    "  mapping_df = pd.DataFrame({\n",
    "      \"State\": list(states.values()),\n",
    "      \"StateAcronyms\": list(states.keys())\n",
    "  })\n",
    "  ans = pd.merge(ans, mapping_df, how='left')\n",
    "  return ans\n",
    "get_list_of_university_towns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-data-analysis",
   "graded_item_id": "Il9Fx",
   "launcher_item_id": "TeDW0",
   "part_id": "WGlun"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}